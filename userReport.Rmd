---
title: Wallace Session `r Sys.Date()`
runtime: shiny
author: "Jamie M. Kass"
date: "May 3rd, 2014"
---

<!-- ```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=FALSE)
``` -->

```{r setup, include=FALSE}
library(knitr)
knit_engines$set(asis = function(options) {
  if (options$echo && options$eval) knit_child(text = options$code)
})
```

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

This is an R Markdown document (for more information see <http://rmarkdown.rstudio.com>). Here all R code history from the Wallace session is recorded and annotated. With this document, users can track the analyses completed in their session and reproduce them by running this file in RStudio.

###Package installation

Wallace uses the following R packages that must be installed before starting. Once installed, load them:
```{r, message = FALSE}
library(devtools)
library(rgbif)
library(maptools)
library(spThin)
library(dismo)
library(rgeos)
library(repmis)
library(maps)
library(ENMeval)
```

Wallace also includes several functions developed to help integrate different packages and some additional functionality. For this reason, it is necessary to load the file 'functions.R', which can be found on Wallace's GitHub page (https://github.com/ndimhypervol/wallace). Download the file, place it in your working directory (use `getwd()`), and then load it:
```{r loadFunctions}
source('/Users/musasabi/Documents/github/wallace/functions.R')
```

###Obtain Occurrence Data
```{r, echo = FALSE}
gbif <- input$gbifName != ""
csv <- !is.null(input$userCSV)
```

Record of analysis for *`r makeCap(input$gbifName)`*. 

```{r gbifoccs}
gbifoccs <- NULL  # make empty gbifoccs to fill when GBIF or user input are called
```

```{asis, echo = gbif}
The search for occurrences was limited to `r input$occurrences` records. Obtain occurrence records of the selected species from GBIF:
```

```{r occSearch, eval = gbif, echo = gbif}
results <- occ_search(scientificName = input$gbifName, limit = input$occurrences, hasCoordinate = TRUE)
```

```{asis, echo = gbif}
Check if all the needed columns were returned in the rgbif call, and if some are missing, add them to results$data.
```

```{r occTblEdits, echo = gbif, eval = gbif}
cols <- c('name','decimalLongitude','decimalLatitude',
                'institutionCode','country', 'stateProvince',
                'locality', 'elevation', 'basisOfRecord')
results <- fixcols(cols, results)
locs.in <- results$data[!is.na(results$data[,3]),][,cols]  # if latitude is NA, remove the row
locs.in <- remDups(locs.in)  # remove rows with duplicate coordinates
gbifoccs <- rbind(gbifoccs, locs.in)  # add these locs to gbifoccs
names(gbifoccs)[1:3] <- c('species','longitude', 'latitude')  # rename these rows
gbifoccs$origID <- row.names(gbifoccs)  # create an ID column
```

```{asis, echo = csv}
User CSV path with occurrence data (change to the path of the file in your computer):
```

```{r input, echo = csv, eval = csv}
inFile <- read.csv(input$userCSV$datapath, header = TRUE)  # load occurrence data
```

```{r clean, echo = csv, eval = csv}
spname <- inFile[1,1]  # get species name
inFile.occs <- inFile[inFile[,1] == spname,]  # limit to records with this name
for (col in c("institutionCode", "country", "stateProvince", "locality", "elevation", "basisOfRecord")) {  # add all cols to match gbifoccs if not already there
  if (!(col %in% names(inFile.occs))) inFile.occs[,col] <- NA
}
inFile.occs$origID <- row.names(inFile.occs)  # add col for IDs
gbifoccs <- rbind(gbifoccs, inFile.occs)  # add the CSV points to existing gbifoccs
gbifoccs <- remDups(gbifoccs)  # remove duplicate records
```

###Process Occurrence Data

